{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create an Image Analysis client\n",
    "client = ImageAnalysisClient(\n",
    "    endpoint='https://westus2.api.cognitive.microsoft.com/',\n",
    "    credential=AzureKeyCredential('07fdb657daed4e34af2541c636ee1a75')\n",
    ")\n",
    "\n",
    "# Get a caption for the image. This will be a synchronously (blocking) call.\n",
    "result = client.analyze_from_url(\n",
    "    image_url=\"https://learn.microsoft.com/azure/ai-services/computer-vision/media/quickstarts/presentation.png\",\n",
    "    visual_features=[VisualFeatures.OBJECTS],\n",
    "    gender_neutral_caption=True,  # Optional (default is False)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_key = \"7c9ff32669cb48b29e076df67c8d60c7\"\n",
    "endpoint = \"https://b03-computevision.cognitiveservices.azure.com/\"\n",
    "\n",
    "\n",
    "def request_vision(image_path, features):\n",
    "    api_url = f\"{endpoint}/computervision/imageanalysis:analyze\"\n",
    "    params = {\n",
    "        \"features\": features,\n",
    "        \"model-version\": \"latest\",\n",
    "        \"language\": \"en\",\n",
    "        \"api-version\": \"2024-02-01\"\n",
    "    }\n",
    "    # 요청 헤더 설정\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": subscription_key,\n",
    "        \"Content-Type\": \"application/octet-stream\"\n",
    "    }\n",
    "\n",
    "    # 요청 데이터 설정\n",
    "    data = {\n",
    "        \"url\": \"https://learn.microsoft.com/azure/ai-services/computer-vision/media/quickstarts/presentation.png\"\n",
    "    }\n",
    "    \n",
    "    with open(image_path,'rb') as image:\n",
    "        image_data = image.read()\n",
    "\n",
    "\n",
    "    response = requests.post(api_url, headers=headers, params=params, data=image_data)\n",
    "    print(response.json())\n",
    "    # 요청 보내기\n",
    "\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    response_json=request_vision(image_path, 'objects')\n",
    "    print(response_json)\n",
    "    \n",
    "    # 받은 데이터를 파싱해서 image에 그린다.  \n",
    "    if \"objectsResult\" in response_json and \"values\" in response_json[\"objectsResult\"]:  \n",
    "        for obj in response_json[\"objectsResult\"][\"values\"]:  \n",
    "            box = obj[\"boundingBox\"]  \n",
    "            x, y, w, h = box[\"x\"], box[\"y\"], box[\"w\"], box[\"h\"]  \n",
    "            print(x, y, w, h)\n",
    "            draw.rectangle([(x, y), (x + w, y + h)], outline=\"red\", width=2)  \n",
    "            if \"tags\" in obj:  \n",
    "                for tag in obj[\"tags\"]:  \n",
    "                    draw.text((x, y - 10), tag[\"name\"], fill=\"red\") \n",
    "    elif 'tagsResult' in response_json and \"values\" in response_json[\"tagsResult\"]:\n",
    "        for obj in response_json['tagsResult']['values']:\n",
    "            print(obj['name'],int(obj['confidence']*100))\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'modelVersion': '2023-10-01', 'metadata': {'width': 816, 'height': 612}, 'objectsResult': {'values': [{'boundingBox': {'x': 141, 'y': 206, 'w': 613, 'h': 231}, 'tags': [{'name': 'tool', 'confidence': 0.718}]}]}}\n",
      "{'modelVersion': '2023-10-01', 'metadata': {'width': 816, 'height': 612}, 'objectsResult': {'values': [{'boundingBox': {'x': 141, 'y': 206, 'w': 613, 'h': 231}, 'tags': [{'name': 'tool', 'confidence': 0.718}]}]}}\n",
      "141 206 613 231\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    input_image = gr.Image(label='이미지 선택',type='filepath')\n",
    "    output_image = gr.Image(label='출력 이미지',type='pil',interactive=False)\n",
    "    \n",
    "    input_image.change(fn=change_image,inputs=[input_image],outputs=[output_image])\n",
    "    \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Image analysis results:\")\n",
    "# Print caption results to the console\n",
    "print(\" Caption:\")\n",
    "if result.caption is not None:\n",
    "    print(f\"   '{result.caption.text}', Confidence {result.caption.confidence:.4f}\")\n",
    "\n",
    "# Print text (OCR) analysis results to the console\n",
    "print(\" Read:\")\n",
    "if result.read is not None:\n",
    "    for line in result.read.blocks[0].lines:\n",
    "        print(f\"   Line: '{line.text}', Bounding box {line.bounding_polygon}\")\n",
    "        for word in line.words:\n",
    "            print(f\"     Word: '{word.text}', Bounding polygon {word.bounding_polygon}, Confidence {word.confidence:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
